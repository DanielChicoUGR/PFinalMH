
\documentclass[a4paper, 12.5pt]{report}

\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{color}
\usepackage{listings}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{dirtree}
% Configuración de los márgenes
\usepackage[a4paper,left=2cm,right=1cm,top=1.7cm,bottom=1.7cm]{geometry}

\usepackage[nottoc, notlot, notlof, notindex]{tocbibind}
\usepackage{algorithmicx} %% Opciones de índice
% Configuración de los encabezados y pies de página
\pagestyle{fancy}
\fancyhf{}
\rhead{\footnotesize\itshape\rightmark}
\lhead{\footnotesize\itshape\nouppercase{\leftmark}}
\rfoot{\thepage}

% Configuración de los espacios entre párrafos
\setlength{\parskip}{1em}

% Configuración de los listados de código
\lstset{basicstyle=\footnotesize\ttfamily, breaklines=true, frame=single, tabsize=2, language=c++}

% Configuración de los enlaces hipervínculos
\hypersetup{colorlinks=true, linkcolor=black, urlcolor=blue, citecolor=black}

% Configuración de las tablas
\setlength{\tabcolsep}{12pt}
\renewcommand{\arraystretch}{1.5}

% Configuración de las leyendas de las figuras
\captionsetup[figure]{font=footnotesize,labelfont=bf,skip=10pt}

% Configuración de las sub-figuras
\captionsetup[subfigure]{font=footnotesize,labelfont=bf,skip=2pt}

% Configuración de las ecuaciones
\allowdisplaybreaks

% Configuración de la fuente del documento
\renewcommand{\familydefault}{\sfdefault}

% Comienza la numeración de las secciones en 1
% \setcounter{section}{1}

\begin{document}


\begin{titlepage}
    \centering
    \includegraphics[width=0.3\textwidth]{logo}\par\vspace{0.75cm}
    {\Large Universidad de Granada \par}
    \vspace{0.75cm}
    {\large Departamento de Ciencias de la Computación e Inteligencia Artificial \par}
    \vspace{1cm}
    {\huge\bfseries Memoria de Prácticas Final de Metaheurísticas\par}
    \vspace{1.25cm}
    {\Large\itshape Daniel Chico\\DNI: 26508525J\\
        Correo: dachival@correo.ugr.es\par}
    \vfill
    {\large\bfseries\itshape Práctica optativa: Implementación del GWO y comparativas aplicando el problema de la competición CEC2017\par}
    \vfill
    {\small Subgrupo: 3}
    \vfill
    {\small Horario: Miercoles (17.30/19.30)}
    \vfill
    {\small Tutor: Daniel Molina}
    \vfill
    {\small \today \par}

    \begin{center}

        \subsection*{Algoritmos Implementados:}
        \begin{itemize}
            \item Grey wolf Optimization
            \item Grey Wolf Optimization - Búsqueda local
                  % \item Grey Wolf Optimization - Enfriamiento simulado
        \end{itemize}

    \end{center}


\end{titlepage}

\tableofcontents


\section{Resumen}\label{sec:resumen}

\subsection{Grey Wolf Optimization}

Para el desarrollo de la práctica alternativa decidí implementar una metaheurística basada en el lobo gris, a partir de ahora será GWO de sus siglas en inglés. Esta metaheurísticas se basa en el comportamiento de las manadas de lobos. Se basa en dos premisas, la gerarquía social dentro de la manada y las técnicas de caza.

De observar la gerarquía de los lobos se pueden distinguir 4 roles entre los que se dividen los individuos de una manada:
\begin{itemize}
    \item $\alpha$: Los jefes de la manada, no son los mas fuertes sino los que tienen una mayor capacidad organizativa
    \item $\beta$: Segundos en el escalafón, realizan tareas organizativas también y apoyan al $\alpha$
    \item $\delta$: Tercer escalafón
    \item $\omega$: últimos en la escala social de la manada, son unos mandados a efectos prácticos, también son los lobos más débiles de la manada.
\end{itemize}


A la hora de cazar los lobos persiguen a su presa hasta que consiguen rodearla y que esta se pare, a partir de ese momento empiezan a atacarlo poco a poco hasta que consigue su objetivo.

\subsubsection{Formalización matemática}
Por lo comentado anteriormente esta metaheurística se basa en modelos poblacionales en el que las peores soluciones de la población son consideradas $\omega_s$ y se modifican en función de un parametro aleatório y una \(''\)suma\(''\) de las distancias a las mejores soluciones. En este caso corresponderían a los lobos $\alpha$,$\beta$ y $\delta$. Este proceso difiere de como cazan los lobos ya que, en problemas de este tipo, no se puede 'divisar' a la presa (solución óptima) para perseguirla asi que se hace la asumpción de que las mejores soluciónes ''saben'' algo sobre la solución óptima e influyen en el comportamiento del resto de la población.

Durante el proceso de caza, los lobos tienden a rodear a su presa primero. matemáticamente se puede formular de la siguiente manera:
$$D=|C*X_p(t)-X(t)| $$
$$X(t+1)=X_p(t)-A*D$$
$$A=2ar_1-r_2$$
$$C=2r_2$$
Donde:
\begin{itemize}
    \item t $\rightarrow$ Iteración actual
    \item $X_p$ $\rightarrow$ Vector posición de la presa
    \item X $\rightarrow$ Posicion de un lobo
    \item A $\rightarrow$ Vector con coeficientes
    \item D $\rightarrow$ Vector con coeficientes
    \item $r_1$ $\rightarrow$ vector aleatorio con coef [0,1]
    \item $r_2$ $\rightarrow$ vector aleatorio con coef [0,1]
    \item a $\rightarrow$ parametro que va de [2,0] y decrece linealmente con el paso de las iteraciones
\end{itemize}


Aunque el proceso de caza es guiado por $\alpha,\beta$ y $\delta$, en un problema en un espacio de búsqueda abstracto, no sabemos la posición de la ''presa'' (solución, óptima o no), para simular la caza, se asume que la cuspide de la gerarquía estiman mejor la posición de la presa y por consiguiente guían al resto de la manada. Esto se puede formular de la siguiente manera:


\begin{itemize}
    \item $D_\alpha=|C_1*X_\alpha(t)-X(t)| $
    \item $D_\beta=|C_2*X_\beta(t)-X(t)| $
    \item $D_\delta=|C_3*X_\delta(t)-X(t)| $
    \item $X_1=X_\alpha(t)-A_1*D_\alpha$
    \item $X_2=X_\beta(t)-A_2*D_\beta$
    \item $X_3=X_\delta(t)-A_3*D_\delta$
    \item $X(t+1)=\frac{X_1+X_2+X_3}{3}$
\end{itemize}

\subsubsection{Características de la Metaheurística}

Es una metaheurística de caracter poblacional, en el que cada lobo es representado como una solución concreta. El tamaño de la muestra, se recomienda que sea de entre 5 y 12 individuos con el objetivo de intentar simular al máximo las manadas de lobos grises salvajes (cuyo numero de integrantes oscila entre esos valores en libertad). Tras varias pruebas he determinado que el tamaño de población que mejor se ajusta al problema es 10 aunque dejo como duda que pasaría si la manda fuera mas grande (llegando a 50 individuos como por ejemplo la práctica 2 donde implementamos técnicas poblacionales con ese número de soluciones para explorar).


El caracter estocástico que tiene esta ''mh'' viene dado por la aparición de dos vectores de vlaores aleatorios que intervienen en el valor de $\vec{A}$ y $\vec{C}$. Para controlar cuando el algoritmo explora y cuando explota el vecindario, se tiene un parametro A que va linealmente de $2 \rightarrow 0$ linealmente a lo largo de las iteraciones. Cuando este parametro es mayor que 1, el agente se desplaza una mayor distancia en la dirección de la presa, ''Saltandosela'' pero explorando otros entornos que pueden dar mejoras soluciones. Cuando este parametro es menor a 1 estas actualizaciones desplazan la solución una menor distancia consiguiendo explotar el entorno definido por los $\alpha,\beta,\delta$.


\subsubsection*{Pseudocódigo}


\begin{algorithm}[H]
    \caption{Grey Wolf Optimization}\label{alg:GWO}
    \begin{algorithmic}[1]
        \Function{GWO}{$n\_sol,fitnes\_func,min,max,max\_evals$}
        \State Inicializamos la población $X_i (i=1,...,N\_SOL)$
        \State for\_each(agente) $ \gets fitnes\_func(agente)$
        \State $X_\alpha \gets$ Mejor Sol de la población
        \State $X_\beta \gets$ Segunda mejor Sol de la población
        \State $X_\delta \gets$ Tercera mejor Sol de la población
        \State $Max\_iters=max\_evals/N_SOL$
        \For{iter $\in$ Max\_Iters}
        \State $a=2*(1-(iter/max\_evals))$
        \State actualiza\_lobos (dim,poblacion,alpha,beta,delta,a)
        \State for\_each(agente) $ \gets fitnes\_func(agente)$

        \State $X_\alpha \gets$ Mejor Sol de la población
        \State $X_\beta \gets$ Segunda mejor Sol de la población
        \State $X_\delta \gets$ Tercera mejor Sol de la población


        \EndFor

        \Return $X_\alpha $
        \EndFunction


    \end{algorithmic}
\end{algorithm}


\begin{algorithm}[H]
    \caption{Actualiza\_lobos}\label{alg:AW}
    \begin{algorithmic}[1]
        \Function{GWO}{$dim,poblacion,alpha,beta,delta,a$}
        \For{$lobo \in Poblacion$}

        \State $D_\alpha=|C_1*X_\alpha(t)-X(t)| $
        \State $D_\beta=|C_2*X_\beta(t)-X(t)| $
        \State $D_\delta=|C_3*X_\delta(t)-X(t)| $
        \State $X_1=X_\alpha(t)-A_1*D_\alpha$
        \State $X_2=X_\beta(t)-A_2*D_\beta$
        \State $X_3=X_\delta(t)-A_3*D_\delta$
        \State $X(t+1)=\frac{X_1+X_2+X_3}{3}$ \Comment{Ajustamos la posición del agente como la media de los desplazamientos hacia $ \alpha,\beta,\delta$}

        \EndFor

        \Return $poblacion$
        \EndFunction


    \end{algorithmic}
\end{algorithm}









\section{Análisis de Rendimientos}

Antes de entrar a valorar como de buena es la metaherística del GWO, se ha de tener en cuenta que las metaheurísticas al ser basadas en comportamientos animales o fenómenos físicos no tienen porqué dar siempre el resultado correcto.
Se intenta aproximar al mejor resultado explorado en el espacio de soluciones.     La calidad de las soluciones depende de si dicha mh se diseña/piensa para el tipo de problema. Las ejecuciones se han realizado con la semilla aleatoria 1.

La calidad de los resultados de la metaheurística se comprobarán a priori con otras 3 metaheurísticas proporcionadas por la web \url{https://tacolab.org} y contra un algoritmo que solo genere soluciones aleatorias.     Esto último podría sonar a algo que no aporta información, pero gracias a los teoremas de \textit{No free lunch} no se puede descartar esta metaheurística (en referencia a la aleatoria). Tampoco sería un algoritmo a escoger para resolver un problema pero si que lo considero como una buena frontera, tanto en cuanto a superar en calidad de soluciones.



\subsection{D10}

\subsubsection*{1\% Ejecuciones}
\input{Resultados/basico/d10/results_1.tex}
\subsubsection*{50\% Ejecuciones}

\input{Resultados/basico/d10/results_50.tex}
\subsubsection*{100\% Ejecuciones}
\input{Resultados/basico/d10/results_100.tex}

\subsubsection*{Media Puestos}
\input{Resultados/basico/d10/results_mean.tex}
\includegraphics*[width=1\textwidth]{Resultados/basico/d10/Grafico_puestos.png} \label{img:ranking_D10}


Aqui se puede ver la media de puestos para 10D. Siendo la cota a superar a priori el random vemos que se lo supera pero no por mucho. Menos al inicio de las iteraciones (donde el componente aleatorio tiene mas predominancia) que obtiene mejores resultados. Fijandonos también en la tabla \ref{table:1_ejecD10}.

En la imagen \ref*{img:ranking_D10} Se puede ver como para D10, esta metaheurística no hace un mejor trabajo que otras técnicas más usadas y conocidas. Es más, para este tipo de funciones, cuando el nuemero de iteraciones se acerca al límite no genera una mejor solución que el algoritmo Random lo cual deja mucho que desear si se quiere usar esta metaheurística para optimizar una función similar.


\subsection{D30}

\subsubsection*{1\% Ejecuciones}

\input{Resultados/basico/d30/results_1.tex}
\subsubsection*{50\% Ejecuciones}
\input{Resultados/basico/d30/results_50.tex}

\subsubsection*{100\% Ejecuciones}
\input{Resultados/basico/d30/results_100.tex}

\subsubsection*{Media Puestos}
\input{Resultados/basico/d30/results_mean.tex}
\includegraphics*[width=1\textwidth]{Resultados/basico/d30/Grafico_puestos.png} \label{img:ranking_D30}
Nuevamente se observa como el algoritmo directamente no es capaz de combatir contra otras metaheurísticas en estos problemas. Por lo que tengo entendido y tras hablar con Daniel (profesor de prácticas), Esta mh se diseñó y testeó con funciones cuyo mínimo se encuentra en el centro del espacio de solución o muy cerca. A tener en cuenta que a diferencia de rendimiento en PSO entre los dos tipos de problemas. Que puede ser debido a los propios operadores del algoritmo que sesguen el espacio de búsqueda.



\section{Hibridación y Análisis de Rendimiento}

Para hibridar el algoritmo de GWO he probado dos versiones. La primera sería una búsqueda local con las características indicadas en el guión de la práctica 1 para el problema del APC. Y la segunda correspondería al algoritmo de Enfriamiento simulado, el cuál usa el esquema de enfriamiento de Cauchí modificado explicado en la práctica 3 de la asignatura, se mantienen otras características indicadas en los guines en los algoritmos implementados.



\subsection{Proceso de Hibridación}

Tanto para el modelo híbrido con enfriamiento simulado como para el de búsqueda local se dan como máximo 200 evaluaciones por ejecución del algoritmo. Estos se ejecutan cada 20 iteraciones sobre los lobos $X_\alpha,X_\beta,X_\delta$ después de calcular los desplazamientos y los nuevos fittnes.

Para decidir que versión comparar con el resto de algoritmos vamos a comparar la version sin hibridar con las otras dos y compararemos la versión hibrida que mejor resultados dé en comparación con su contrincante.


\subsubsection*{Dimensión 10}

\includegraphics*[width=0.5\textwidth]{Resultados/hibrido/Interno/D10/media_posicion.png} \label{img:media_posicion_D10_comparativa}

\input{Resultados/hibrido/Interno/D10/results_mean.tex}
\includegraphics*[width=0.5\textwidth]{Resultados/hibrido/Interno/D10/ev_error.png} \label{img:error_D10_comparativa}

\subsubsection*{Dimensión 30}

\includegraphics*[width=0.5\textwidth]{Resultados/hibrido/Interno/D30/media_posicion.png} \label{img:media_posicion_D30_comparativa}

\input{Resultados/hibrido/Interno/D30/results_mean.tex}

\includegraphics*[width=0.5\textwidth]{Resultados/hibrido/Interno/D30/ev_error.png} \label{img:error_D30_comparativa}

\subsubsection*{Analisis y toma de decisiones}
Ambas versiones proporcionan unos mejores resultados. Siendo la versión de enfriamiento simulado la que gana por poco. Por los resultados de las prácticas tenía cierta noción de que enfriamiento simulado funciona mejor. Ahora con estos resultados, y despues de probarlos en dos tipos de problemas puedo confirmarlo. La probailidad de aceptar peores soluciones hace que se estanque en menos minimos locáles y acabe acercandose más a los minimos globales. También queda claro que, aunque el algoritmo base del GWO tiene mecanismos para explotar el entorno siempre viene bién utilizar metaheurísticas pensadas para ese objetivo ya que tenderán a mejorar más los resultados.

Para el análisis con el resto de algoritmos usaré a partir de ahora el algoritmo hibridado con la búsqueda local. Esta será la versión que se ejecute por defecto en el ejecutable cuando se escoja la version hibridada. Para mas información al respecto acuda a \ref{subsec:set-up}



\subsection{Análisis del rendimiento}

\subsubsection{1\% de Evaluaciones}

\subsubsection{50\% de Evaluaciones}

\subsubsection{100\% de Evaluaciones}


\section{Procedimientos}

Para el desarrollo de la práctica se ha usado el lenguaje de programación C++. Los motivos de esta decisión son: la familiaridad con el lenguaje de programación y el rendimiento superior a lenguajes de programación de alto nivel, conveniente para el tratamiento de grandes cantidades de datos, o la resolución de problemas computacionalmente intensivos.

Para la compilación del código se ha usado el compilador clang. La estructura del proyecto se ha configurado usando CMAKE. Para la ejecución de los programas se ha usado el sistema operativo Linux. Aunque al usar CMAKE se podría generar un proyecto para Windows.

\subsection{Estructura del proyecto}

El proyecto se ha estructurado de la siguiente manera:


\dirtree{%
    .1 code.
    .2 SRC \DTcomment{Carpeta con el código fuente del proyecto}.
    .2 INCLUDE \DTcomment{Carpeta con los archivos de cabecera del proyecto}.
    .2 Input\_data \DTcomment{Carpeta con los datos para ejecutar los algoritmos}.
    .2 CMakeList.text \DTcomment{Archivo de configuración CMAKE}.
    .2 build \DTcomment{Carpeta donde se recomienda generar los archivos de compilación de CMAKE en caso de compilar}.
    .2 extract\_all.py \DTcomment{Archivo de ejecución de extract.py}.
    .2 extract.py \DTcomment{Genera una hoja de calculo con los archivos de resultado}.
    .2 genera\_medias.py \DTcomment{Genera la media de las distintas ejecuciones en una hoja de calculo para su posterior analisis}.
    .2 Modifica\_tablas.py \DTcomment{Modifica las tablas en latex de \url{tacolab.org} para que estén bien formateadas}.
    .2 Memoria.pdf.
}


\subsection{Set Up} \label{subsec:set-up}

Se le entregará un archivo .zip llamado software que contendrá la estructura de directorios anterior. La carpeta build estará vacía por cuestiones obvias y en la carpeta bin se hallarán distintos ejecutables, todos del mismo código, compilado para varias plataformas directamente.

Si su plataforma no está entre las pre-compiladas siga leyendo este apartado, sino, salte al apartado de ejecución.

Si no puede ejecutar ninguno de los ejecutables. Deberá tener un compilador de c++ instalado en su computador y el programa \textbf{\textit{CMAKE}} y \textbf{\textit{make}}  para seguir con el tutorial.


\subsubsection*{Linux}

\begin{enumerate}
    \item Abra una terminal en la raíz del proyecto
    \item Si no está creada la carpeta build (que no debería), créela, sino pase al paso 3
          \begin{itemize}
              \item \begin{lstlisting}[language=bash]
				mkdir build
            \end{lstlisting}
          \end{itemize}
    \item Acceda a la carpeta build e inicialice el proyecto
          \begin{itemize}
              \item \begin{lstlisting}[language=bash]
				cd build
				cmake ..
				cd ..
				cmake -DCMAKE_BUILD_TYPE=Debug -S . -B build
            \end{lstlisting}
          \end{itemize}
    \item Compile el programa
          \begin{itemize}
              \item \begin{lstlisting}[language=bash]
				cmake --build build --target main
            \end{lstlisting}
          \end{itemize}
\end{enumerate}

\subsubsection{Windows}

El programa se ha escrito pensando en ejecutarse en Linux, si se tiene un sistema Windows lo que se recomienda es usar WSL, instalar el compilador de c++ GNU y CMAKE en esa máquina virtual y ejecutar desde ahí, siguiendo las instrucciones del apartado anterior.

\subsection{Ejecución}

Para la ejecución del programa se ha pensado en pasar los parámetros siempre por línea de comandos. El programa permite configurar que ejecutar y como de la siguiente manera:

Por orden aparecen primeros los obligatorios y después los flags. Si llevan un guion delante, es un flag y, por tanto, optativo

\section{Bibliografía}

Principalmente, documentos de la universidad apoyados del siguiente libro:

\url{https://www.google.com/search?q=The+algorithm+Design+Manual&oq=The+algorithm+Design+Manual&aqs=chrome..69i57.8716j0j1&sourceid=chrome&ie=UTF-8#wptab=si:AMnBZoEG3b_8oGF0zZDE6xv96fMHXP7HJH_MnzBXKd6lQPgr0x9FAhJbzhl-mXQs09va7tgfS0tmq9BAixznV7von37XNewIw_Um1FQ6wfaQI4rwDvhX1e-GXS_G0MX7E6K2fWcdKuVs64FZpIqGagHPROC0mvbWvcSAQYL-QLu2yIPStw0Zslk%3D}


\end{document}
